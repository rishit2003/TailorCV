# Phase 3: CV Embedding & Vector Database Integration âœ…

## ðŸŽ¯ What We Achieved

Successfully implemented **asynchronous CV embedding** using RabbitMQ, BGE-base model, and Pinecone VectorDB. CVs are now automatically chunked, embedded, and stored for semantic search.

---

## ðŸ“Š Understanding the SCORE in Pinecone

The **SCORE** you see (e.g., 0.7031, 0.5069) is a **cosine similarity score** from Pinecone vector search:

- **Range**: 0.0 to 1.0
- **Meaning**: How similar a CV chunk is to your search query
- **0.7+**: Very relevant match
- **0.5-0.7**: Moderate match
- **<0.5**: Weak match

**Example**: If you search for "Python developer", chunks with Python experience will have scores like 0.85, while unrelated chunks might be 0.30.

**Note**: This is different from the CV scoring system (0-100) used in the `/api/score` endpoint.

---

## ðŸ”„ Complete Flow: Upload to Pinecone Storage

### Step-by-Step Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend   â”‚ User uploads CV (text or PDF)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ POST /api/upload_cv_text or /api/upload_cv_pdf
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Gateway     â”‚ Extracts PDF text (if PDF), forwards to services
â”‚  (Port 8000)     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                                         â”‚
       â–¼                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GeminiService    â”‚                    â”‚ StoringService   â”‚
â”‚ (Port 8002)      â”‚                    â”‚ (Port 8001)      â”‚
â”‚                  â”‚                    â”‚                  â”‚
â”‚ Structures CV    â”‚                    â”‚ Stores in MongoDBâ”‚
â”‚ using Gemini AI  â”‚                    â”‚ Calculates hash  â”‚
â”‚                  â”‚                    â”‚ (cv_id)          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                       â”‚
       â”‚ Returns structured_sections           â”‚
       â”‚                                       â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   StoringService      â”‚
              â”‚   Publishes Event     â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ publish_cv_event(cv_id)
                          â”‚
                          â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   RabbitMQ Queue      â”‚
              â”‚   cv_embedding_queue  â”‚
              â”‚                       â”‚
              â”‚   Message:            â”‚
              â”‚   {"cv_id": "..."}    â”‚
              â”‚                       â”‚
              â”‚   ðŸ“ˆ SPIKE APPEARS    â”‚
              â”‚   (Unacked: 1)        â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ Consumer picks up message
                          â”‚
                          â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   VectorService       â”‚
              â”‚   (Port 8003)         â”‚
              â”‚                       â”‚
              â”‚   1. Fetch CV from    â”‚
              â”‚      StoringService   â”‚
              â”‚   2. Chunk sections   â”‚
              â”‚   3. Embed chunks     â”‚
              â”‚   4. Upload to        â”‚
              â”‚      Pinecone         â”‚
              â”‚   5. ACK message      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ Message acknowledged
                          â”‚
                          â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   RabbitMQ Queue      â”‚
              â”‚                       â”‚
              â”‚   ðŸ“‰ SPIKE DISAPPEARS â”‚
              â”‚   (Ready: 0)          â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Pinecone VectorDB   â”‚
              â”‚   tailorcv-cv-chunks  â”‚
              â”‚                       â”‚
              â”‚   âœ… 20 chunks stored â”‚
              â”‚   (768-dim vectors)   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“¨ RabbitMQ Message Lifecycle

### Timeline Visualization

```
Time    Event                          RabbitMQ Status
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
T0      CV uploaded                   Queue: 0 messages
T1      StoringService publishes       Queue: 1 message (Ready)
                                        ðŸ“ˆ SPIKE APPEARS
T2      VectorService receives        Queue: 1 message (Unacked)
T3      VectorService processing...    Queue: 1 message (Unacked)
        (fetching, chunking, embedding)
T4      VectorService uploads to       Queue: 1 message (Unacked)
        Pinecone
T5      VectorService ACKs message     Queue: 0 messages
                                        ðŸ“‰ SPIKE DISAPPEARS
```

### Key Points:

1. **Spike Appears**: When `StoringService` publishes `cv_id` to RabbitMQ
2. **Spike Stays**: While `VectorService` is processing (message is "Unacked")
3. **Spike Disappears**: When `VectorService` sends `basic_ack()` after successful upload

### RabbitMQ Dashboard Indicators:

- **Ready**: Messages waiting to be consumed
- **Unacked**: Messages being processed (spike visible)
- **Total**: Ready + Unacked

---

## ðŸ› ï¸ Phase 3 Implementation Details

### 1. Intelligent Chunking Logic (`vector_service/app/embedder.py`)

**Strategy**: Semantic, type-based chunking for optimal embedding quality.

#### Chunking Rules:

| Section Type | Chunking Strategy | Example |
|-------------|-------------------|---------|
| **Experience** | Each bullet point = 1 chunk | "Led team of 5 developers" â†’ separate chunk |
| **Projects** | Each bullet point = 1 chunk | "Built REST API with FastAPI" â†’ separate chunk |
| **Summary** | Entire text = 1 chunk | Full summary paragraph |
| **Skills** | All skills combined = 1 chunk | "Python, Java, Docker, Kubernetes" |
| **Education** | Each degree = 1 chunk | "BSc Computer Science - Concordia" |
| **Leadership** | Each role = 1 chunk | "Mentor - Co-op - Concordia University" |
| **Certifications** | Each cert = 1 chunk | "AWS Certified Solutions Architect" |

#### Code Structure:

```python
def chunk_structured_sections(structured_sections, cv_id):
    """
    Intelligently chunks CV sections for embedding.
    
    Returns: List of chunks with:
    - cv_id: CV identifier
    - section: Section name (experience, projects, etc.)
    - text: Chunk text content
    - metadata: Additional context (company, title, dates, etc.)
    """
```

**Result**: Your CV created **20 chunks**:
- 9 experience chunks (one per bullet)
- 8 project chunks (one per bullet)
- 3 other chunks (summary, skills, education/leadership)

---

### 2. Embedding Model (`vector_service/app/embedder.py`)

**Model**: `BAAI/bge-base-en-v1.5`
- **Dimension**: 768 (reduced from 1024 to avoid memory issues)
- **Type**: Sentence Transformer
- **Purpose**: Converts text chunks into 768-dimensional vectors

**Why BGE-base instead of BGE-large?**
- BGE-large (1024 dim) caused "paging file too small" errors on Windows
- BGE-base (768 dim) uses less memory and works reliably
- Still provides excellent semantic search quality

**Loading Strategy**:
- Model loaded once on startup (cached globally)
- Reused for all embedding operations
- Prevents repeated downloads

---

### 3. Pinecone Integration (`vector_service/app/pinecone_client.py`)

**Index**: `tailorcv-cv-chunks`
- **Dimension**: 768 (matches BGE-base)
- **Metric**: Cosine similarity
- **Cloud**: AWS (us-east-1)
- **Type**: Serverless

**Auto-Index Management**:
- Detects if index exists
- Checks dimension compatibility
- Auto-deletes and recreates if dimension mismatch (only if empty)
- Prevents dimension errors

**Upsert Strategy**:
- Batch upsert (100 vectors per request)
- Unique IDs: `{cv_id}_{section}_{chunk_index}`
- Metadata includes: `cv_id`, `section`, `text`, and section-specific fields

**Example Vector ID**:
```
8a5b9213..._experience_0
8a5b9213..._projects_11
8a5b9213..._leadership_19
```

---

### 4. RabbitMQ Consumer (`vector_service/app/mq_consumer.py`)

**Queue**: `cv_embedding_queue`
- **Durable**: Yes (survives RabbitMQ restart)
- **Prefetch**: 1 (process one message at a time)

**Error Handling**:
- **Memory/Paging Errors**: NOT requeued (prevents infinite loop)
- **Network Errors**: Requeued for retry
- **Other Errors**: Requeued for retry

**Consumer Flow**:
```python
def callback(ch, method, properties, body):
    1. Parse cv_id from message
    2. Call process_cv_for_embedding(cv_id)
    3. If success: basic_ack() â†’ message removed
    4. If memory error: basic_nack(requeue=False) â†’ message discarded
    5. If other error: basic_nack(requeue=True) â†’ retry later
```

**Key Fix**: Prevents infinite loops by detecting memory errors and NOT requeuing them.

---

### 5. Service Orchestration (`vector_service/app/service.py`)

**Main Function**: `process_cv_for_embedding(cv_id)`

**Flow**:
1. Fetch CV from StoringService (`GET /internal/get_cv/{cv_id}`)
2. Extract `structured_sections` from CV document
3. Chunk sections using intelligent algorithm
4. Embed chunks using BGE-base model
5. Upload embedded chunks to Pinecone

**Error Handling**:
- Raises exceptions on failure
- Consumer handles retry logic
- Logs all steps for debugging

---

## ðŸ“ˆ What Happens in RabbitMQ Dashboard

### Before Upload:
- **Ready**: 0
- **Unacked**: 0
- **Total**: 0
- **Graph**: Flat line at 0

### During Processing:
- **Ready**: 0
- **Unacked**: 1 (message being processed)
- **Total**: 1
- **Graph**: Red spike at 1.0

### After Processing:
- **Ready**: 0
- **Unacked**: 0
- **Total**: 0
- **Graph**: Returns to 0 (spike disappears)

---

## âœ… Testing Results

### Successful Upload:
```
âœ… CV uploaded via frontend
âœ… Structured by GeminiService
âœ… Stored in MongoDB
âœ… Published to RabbitMQ
âœ… Consumed by VectorService
âœ… Chunked into 20 semantic units
âœ… Embedded using BGE-base (768-dim)
âœ… Uploaded to Pinecone
âœ… RabbitMQ message acknowledged
âœ… Queue empty
```

### Pinecone Verification:
- **Index**: `tailorcv-cv-chunks`
- **Dimension**: 768 âœ…
- **Record Count**: 20 âœ…
- **Chunks Visible**: Yes âœ…

---

## ðŸ” Key Files Modified/Created

### New Files:
- `vector_service/app/embedder.py` - Chunking and embedding logic
- `vector_service/app/pinecone_client.py` - Pinecone integration
- `vector_service/app/mq_consumer.py` - RabbitMQ consumer
- `vector_service/app/service.py` - Service orchestration

### Modified Files:
- `storing_service/app/events.py` - Added RabbitMQ publisher
- `storing_service/app/service.py` - Added publish call after CV storage
- `vector_service/app/main.py` - Added RabbitMQ consumer startup
- `vector_service/requirements.txt` - Added dependencies (pinecone, sentence-transformers, pika)

---

## ðŸŽ“ Technical Decisions

### 1. Why Semantic Chunking?
- **Granularity**: Each bullet point is searchable independently
- **Context**: Metadata preserves company, title, dates
- **Quality**: Better embedding quality than large paragraphs

### 2. Why BGE-base?
- **Memory**: Fits in system memory (no paging file errors)
- **Quality**: Still excellent for semantic search
- **Speed**: Faster than BGE-large

### 3. Why Async Processing?
- **Non-blocking**: CV upload returns immediately
- **Scalable**: Can process multiple CVs in parallel
- **Resilient**: Failed CVs don't block new uploads

### 4. Why Pinecone?
- **Managed**: No infrastructure to maintain
- **Fast**: Sub-millisecond search
- **Scalable**: Handles millions of vectors

---

## ðŸš€ Next Steps (Future Phases)

1. **Similarity Search**: Implement `search_top_k_cvs` endpoint
2. **Tailored Bullets**: Generate job-specific bullet points using similar chunks
3. **Batch Upload**: Process 5000 CVs dataset
4. **Redis Caching**: Cache latest CV for faster retrieval

---

## ðŸ“ Summary

**Phase 3 Status**: âœ… **COMPLETE**

- âœ… Asynchronous embedding pipeline working
- âœ… Intelligent chunking implemented
- âœ… BGE-base embedding integrated
- âœ… Pinecone storage functional
- âœ… RabbitMQ consumer with error handling
- âœ… End-to-end flow tested and verified

**Your CV is now searchable in Pinecone!** ðŸŽ‰

